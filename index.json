[{"authors":["admin"],"categories":null,"content":"Benjamin Heinzerling specializes in natural language processing and computational linguistics, with a research focus on understanding how language models internally represent and process information. His work explores how these models encode numerical properties, track entities, store relational knowledge, and represent factual information. Through publications at leading conferences such as ACL and EMNLP, his research contributes to deeper insights into the internal mechanisms of modern language models and advances our understanding of how they learn and retain knowledge.\nHe serves as Deputy Team Director of the RIKEN AIP Natural Language Understanding Team and holds the position of Specially Appointed Associate Professor at the Tohoku University Center for Language AI Research. His academic background includes a PhD in computational linguistics from Heidelberg University.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://bheinzerling.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Benjamin Heinzerling specializes in natural language processing and computational linguistics, with a research focus on understanding how language models internally represent and process information. His work explores how these models encode numerical properties, track entities, store relational knowledge, and represent factual information. Through publications at leading conferences such as ACL and EMNLP, his research contributes to deeper insights into the internal mechanisms of modern language models and advances our understanding of how they learn and retain knowledge.","tags":null,"title":"Benjamin Heinzerling","type":"authors"},{"authors":["Benjamin Heinzerling","Kentaro Inui"],"categories":[],"content":"","date":1722470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"5d161df7c5b57ad16330cad9880a12b6","permalink":"https://bheinzerling.github.io/publication/heinzerling-2024-monotonic/","publishdate":"2024-10-20T23:51:07.413284Z","relpermalink":"/publication/heinzerling-2024-monotonic/","section":"publication","summary":"","tags":[],"title":"Monotonic Representation of Numeric Attributes in Language Models","type":"publication"},{"authors":["Ana Brassard","Benjamin Heinzerling","Keito Kudo","Keisuke Sakaguchi","Kentaro Inui"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"e22a6d8d1882ec8cd87aff8dd9410b52","permalink":"https://bheinzerling.github.io/publication/brassard-2024-acorn/","publishdate":"2024-10-20T23:51:07.267284Z","relpermalink":"/publication/brassard-2024-acorn/","section":"publication","summary":"","tags":[],"title":"ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation","type":"publication"},{"authors":["Ryosuke Takahashi","Go Kamoda","Benjamin Heinzerling","Keisuke Sakaguchi","Kentaro Inui"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"635c2a3e47625833d9358a4084753639","permalink":"https://bheinzerling.github.io/publication/takahashi-2024-curse/","publishdate":"2024-10-20T23:51:06.947748Z","relpermalink":"/publication/takahashi-2024-curse/","section":"publication","summary":"","tags":[],"title":"The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models","type":"publication"},{"authors":["Go Kamoda","Benjamin Heinzerling","Keisuke Sakaguchi","Kentaro Inui"],"categories":[],"content":"","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"b8f678837f8a070649d674d52f23bed0","permalink":"https://bheinzerling.github.io/publication/kamoda-2023-test/","publishdate":"2024-10-20T23:51:07.507781Z","relpermalink":"/publication/kamoda-2023-test/","section":"publication","summary":"Factual probing is a method that uses prompts to test if a language model ``knows″ certain world knowledge facts. A problem in factual probing is that small changes to the prompt can lead to large changes in model output. Previous work aimed to alleviate this problem by optimizing prompts via text mining or fine-tuning. However, such approaches are relation-specific and do not generalize to unseen relation types. Here, we propose to use test-time augmentation (TTA) as a relation-agnostic method for reducing sensitivity to prompt variations by automatically augmenting and ensembling prompts at test time. Experiments show improved model calibration, i.e., with TTA, model confidence better reflects prediction accuracy. Improvements in prediction accuracy are observed for some models, but for other models, TTA leads to degradation. Error analysis identifies the difficulty of producing high-quality prompt variations as the main challenge for TTA.","tags":[],"title":"Test-time Augmentation for Factual Probing","type":"publication"},{"authors":["Haruki Nagasawa","Benjamin Heinzerling","Kazuma Kokuta","Kentaro Inui"],"categories":[],"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"2d71d45ad8d493d1464be029334644f6","permalink":"https://bheinzerling.github.io/publication/nagasawa-2023-lms/","publishdate":"2024-10-20T23:51:07.63319Z","relpermalink":"/publication/nagasawa-2023-lms/","section":"publication","summary":"","tags":[],"title":"Can LMs Store and Retrieve 1-to-N Relational Knowledge?","type":"publication"},{"authors":["Pride Kavumba","Ana Brassard","Benjamin Heinzerling","Kentaro Inui"],"categories":[],"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"3c1603a01b62251ce538a1a1b1e8f3f3","permalink":"https://bheinzerling.github.io/publication/kavumba-2023-prompting/","publishdate":"2024-10-20T23:51:07.753778Z","relpermalink":"/publication/kavumba-2023-prompting/","section":"publication","summary":"","tags":[],"title":"Prompting for explanations improves Adversarial NLI. Is this true? Yes it is true because it weakens superficial cues","type":"publication"},{"authors":["Teven Le Scao","Angela Fan","Christopher Akiki","Ellie Pavlick","Suzana Ilić","Daniel Hesslow","Roman Castagné","Alexandra Sasha Luccioni","François Yvon","Matthias Gallé","Jonathan Tow","Alexander M. Rush","Stella Biderman","Albert Webson","Pawan Sasanka Ammanamanchi","Thomas Wang","Benoît Sagot","Niklas Muennighoff","Albert Villanova del Moral","Olatunji Ruwase","Rachel Bawden","Stas Bekman","Angelina McMillan-Major","Iz Beltagy","Huu Nguyen","Lucile Saulnier","Samson Tan","Pedro Ortiz Suarez","Victor Sanh","Hugo Laurençon","Yacine Jernite","Julien Launay","Margaret Mitchell","Colin Raffel","Aaron Gokaslan","Adi Simhi","Aitor Soroa","Alham Fikri Aji","Amit Alfassy","Anna Rogers","Ariel Kreisberg Nitzav","Canwen Xu","Chenghao Mou","Chris Emezue","Christopher Klamm","Colin Leong","Daniel van Strien","David Ifeoluwa Adelani","Dragomir Radev","Eduardo González Ponferrada","Efrat Levkovizh","Ethan Kim","Eyal Bar Natan","Francesco De Toni","Gérard Dupont","Germán Kruszewski","Giada Pistilli","Hady Elsahar","Hamza Benyamina","Hieu Tran","Ian Yu","Idris Abdulmumin","Isaac Johnson","Itziar Gonzalez-Dios","Javier de la Rosa","Jenny Chim","Jesse Dodge","Jian Zhu","Jonathan Chang","Jörg Frohberg","Joseph Tobing","Joydeep Bhattacharjee","Khalid Almubarak","Kimbo Chen","Kyle Lo","Leandro Von Werra","Leon Weber","Long Phan","Loubna Ben allal","Ludovic Tanguy","Manan Dey","Manuel Romero Muñoz","Maraim Masoud","María Grandury","Mario Šaško","Max Huang","Maximin Coavoux","Mayank Singh","Mike Tian-Jian Jiang","Minh Chien Vu","Mohammad A. Jauhar","Mustafa Ghaleb","Nishant Subramani","Nora Kassner","Nurulaqilla Khamis","Olivier Nguyen","Omar Espejel","Ona de Gibert","Paulo Villegas","Peter Henderson","Pierre Colombo","Priscilla Amuok","Quentin Lhoest","Rheza Harliman","Rishi Bommasani","Roberto Luis López","Rui Ribeiro","Salomey Osei","Sampo Pyysalo","Sebastian Nagel","Shamik Bose","Shamsuddeen Hassan Muhammad","Shanya Sharma","Shayne Longpre","Somaieh Nikpoor","Stanislav Silberberg","Suhas Pai","Sydney Zink","Tiago Timponi Torrent","Timo Schick","Tristan Thrush","Valentin Danchev","Vassilina Nikoulina","Veronika Laippala","Violette Lepercq","Vrinda Prabhu","Zaid Alyafeai","Zeerak Talat","Arun Raja","Benjamin Heinzerling","Chenglei Si","Davut Emre Taşar","Elizabeth Salesky","Sabrina J. Mielke","Wilson Y. Lee","Abheesht Sharma","Andrea Santilli","Antoine Chaffin","Arnaud Stiegler","Debajyoti Datta","Eliza Szczechla","Gunjan Chhablani","Han Wang","Harshit Pandey","Hendrik Strobelt","Jason Alan Fries","Jos Rozen","Leo Gao","Lintang Sutawika","M Saiful Bari","Maged S. Al-shaibani","Matteo Manica","Nihal Nayak","Ryan Teehan","Samuel Albanie","Sheng Shen","Srulik Ben-David","Stephen H. Bach","Taewoon Kim","Tali Bers","Thibault Fevry","Trishala Neeraj","Urmish Thakker","Vikas Raunak","Xiangru Tang","Zheng-Xin Yong","Zhiqing Sun","Shaked Brody","Yallow Uri","Hadar Tojarieh","Adam Roberts","Hyung Won Chung","Jaesung Tae","Jason Phang","Ofir Press","Conglong Li","Deepak Narayanan","Hatim Bourfoune","Jared Casper","Jeff Rasley","Max Ryabinin","Mayank Mishra","Minjia Zhang","Mohammad Shoeybi","Myriam Peyrounette","Nicolas Patry","Nouamane Tazi","Omar Sanseviero","Patrick von Platen","Pierre Cornette","Pierre François Lavallée","Rémi Lacroix","Samyam Rajbhandari","Sanchit Gandhi","Shaden Smith","Stéphane Requena","Suraj Patil","Tim Dettmers","Ahmed Baruwa","Amanpreet Singh","Anastasia Cheveleva","Anne-Laure Ligozat","Arjun Subramonian","Aurélie Névéol","Charles Lovering","Dan Garrette","Deepak Tunuguntla","Ehud Reiter","Ekaterina Taktasheva","Ekaterina Voloshina","Eli Bogdanov","Genta Indra Winata","Hailey Schoelkopf","Jan-Christoph Kalo","Jekaterina Novikova","Jessica Zosa Forde","Jordan Clive","Jungo Kasai","Ken Kawamura","Liam Hazan","Marine Carpuat","Miruna Clinciu","Najoung Kim","Newton Cheng","Oleg Serikov","Omer Antverg","Oskar van der Wal","Rui Zhang","Ruochen Zhang","Sebastian Gehrmann","Shachar Mirkin","Shani Pais","Tatiana Shavrina","Thomas Scialom","Tian Yun","Tomasz Limisiewicz","Verena Rieser","Vitaly Protasov","Vladislav Mikhailov","Yada Pruksachatkun","Yonatan Belinkov","Zachary Bamberger","Zdeněk Kasner","Alice Rueda","Amanda Pestana","Amir Feizpour","Ammar Khan","Amy Faranak","Ana Santos","Anthony Hevia","Antigona Unldreaj","Arash Aghagol","Arezoo Abdollahi","Aycha Tammour","Azadeh HajiHosseini","Bahareh Behroozi","Benjamin Ajibade","Bharat Saxena","Carlos Muñoz Ferrandis","Daniel McDuff","Danish Contractor","David Lansky","Davis David","Douwe Kiela","Duong A. Nguyen","Edward Tan","Emi Baylor","Ezinwanne Ozoani","Fatima Mirza","Frankline Ononiwu","Habib Rezanejad","Hessie Jones","Indrani Bhattacharya","Irene Solaiman","Irina Sedenko","Isar Nejadgholi","Jesse Passmore","Josh Seltzer","Julio Bonis Sanz","Livia Dutra","Mairon Samagaio","Maraim Elbadri","Margot Mieskes","Marissa Gerchick","Martha Akinlolu","Michael McKenna","Mike Qiu","Muhammed Ghauri","Mykola Burynok","Nafis Abrar","Nazneen Rajani","Nour Elkott","Nour Fahmy","Olanrewaju Samuel","Ran An","Rasmus Kromann","Ryan Hao","Samira Alizadeh","Sarmad Shubber","Silas Wang","Sourav Roy","Sylvain Viguier","Thanh Le","Tobi Oyebade","Trieu Le","Yoyo Yang","Zach Nguyen","Abhinav Ramesh Kashyap","Alfredo Palasciano","Alison Callahan","Anima Shukla","Antonio Miranda-Escalada","Ayush Singh","Benjamin Beilharz","Bo Wang","Caio Brito","Chenxi Zhou","Chirag Jain","Chuxin Xu","Clémentine Fourrier","Daniel León Periñán","Daniel Molano","Dian Yu","Enrique Manjavacas","Fabio Barth","Florian Fuhrimann","Gabriel Altay","Giyaseddin Bayrak","Gully Burns","Helena U. Vrabec","Imane Bello","Ishani Dash","Jihyun Kang","John Giorgi","Jonas Golde","Jose David Posada","Karthik Rangasai Sivaraman","Lokesh Bulchandani","Lu Liu","Luisa Shinzato","Madeleine Hahn de Bykhovetz","Maiko Takeuchi","Marc Pàmies","Maria A Castillo","Marianna Nezhurina","Mario Sänger","Matthias Samwald","Michael Cullan","Michael Weinberg","Michiel De Wolf","Mina Mihaljcic","Minna Liu","Moritz Freidank","Myungsun Kang","Natasha Seelam","Nathan Dahlberg","Nicholas Michio Broad","Nikolaus Muellner","Pascale Fung","Patrick Haller","Ramya Chandrasekhar","Renata Eisenberg","Robert Martin","Rodrigo Canalli","Rosaline Su","Ruisi Su","Samuel Cahyawijaya","Samuele Garda","Shlok S Deshmukh","Shubhanshu Mishra","Sid Kiblawi","Simon Ott","Sinee Sang-aroonsiri","Srishti Kumar","Stefan Schweter","Sushil Bharati","Tanmay Laud","Théo Gigant","Tomoya Kainuma","Wojciech Kusa","Yanis Labrak","Yash Shailesh Bajaj","Yash Venkatraman","Yifan Xu","Yingxin Xu","Yu Xu","Zhe Tan","Zhongli Xie","Zifan Ye","Mathilde Bras","Younes Belkada","Thomas Wolf"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468268,"objectID":"48e50937b3710c8db8bf2f69852bfd77","permalink":"https://bheinzerling.github.io/publication/workshop-2023-bloom-176-bparameteropenaccessmultilingual/","publishdate":"2024-10-20T23:51:08.086205Z","relpermalink":"/publication/workshop-2023-bloom-176-bparameteropenaccessmultilingual/","section":"publication","summary":"","tags":[],"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","type":"publication"},{"authors":["S. Sasaki","Benjamin Heinzerling","Jun Suzuki","Kentaro Inui"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468267,"objectID":"5867595b9616b72ce34f755c4c72c0b1","permalink":"https://bheinzerling.github.io/publication/sasaki-2023-whitening/","publishdate":"2024-10-20T23:51:07.849968Z","relpermalink":"/publication/sasaki-2023-whitening/","section":"publication","summary":"","tags":[],"title":"Examining the effect of whitening on static and contextualized word embeddings","type":"publication"},{"authors":["Qin Dai","Benjamin Heinzerling","Kentaro Inui"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468268,"objectID":"8907eece2491c17c1f492f031bfa2f21","permalink":"https://bheinzerling.github.io/publication/dai-2022-cross/","publishdate":"2024-10-20T23:51:08.202451Z","relpermalink":"/publication/dai-2022-cross/","section":"publication","summary":"","tags":[],"title":"Cross-stitching Text and Knowledge Graph Encoders for Distantly Supervised Relation Extraction","type":"publication"},{"authors":["Yuta Matsumoto","Benjamin Heinzerling","Masashi Yoshikawa","Kentaro Inui"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468268,"objectID":"4c4771a38ff314e31a91b71408d53aed","permalink":"https://bheinzerling.github.io/publication/matsumoto-2022-tracing/","publishdate":"2024-10-20T23:51:07.965134Z","relpermalink":"/publication/matsumoto-2022-tracing/","section":"publication","summary":"","tags":[],"title":"Tracing and Manipulating intermediate values in Neural Math Problem Solvers","type":"publication"},{"authors":["Ana Brassard","Benjamin Heinzerling","Pride Kavumba","Kentaro Inui"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468268,"objectID":"0af7e0dee35b55f8775c503139283738","permalink":"https://bheinzerling.github.io/publication/brassard-2022-copa/","publishdate":"2024-10-20T23:51:08.305231Z","relpermalink":"/publication/brassard-2022-copa/","section":"publication","summary":"","tags":[],"title":"COPA-SSE: Semi-structured Explanations for Commonsense Reasoning","type":"publication"},{"authors":["Benjamin Heinzerling","Kentaro Inui"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"e2faf9815180499239b5cffc9713a23c","permalink":"https://bheinzerling.github.io/publication/heinzerling-2021-language/","publishdate":"2021-03-16T09:22:39.46039Z","relpermalink":"/publication/heinzerling-2021-language/","section":"publication","summary":"","tags":null,"title":"Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries","type":"publication"},{"authors":["Pride Kavumba","Benjamin Heinzerling","Ana Brassard","Kentaro Inui"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"dbc9a6fbbb89cffe4d288acebbb45228","permalink":"https://bheinzerling.github.io/publication/kavumba-2021-learning/","publishdate":"2021-08-24T17:24:30.60044Z","relpermalink":"/publication/kavumba-2021-learning/","section":"publication","summary":"","tags":null,"title":"Learning to Learn to be Right for the Right Reasons","type":"publication"},{"authors":["Benjamin Heinzerling"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"70f7a0ae11e30f6279e40b1cecd9c8fb","permalink":"https://bheinzerling.github.io/thegradient.pub/nlps-clever-hans-moment-has-arrived/","publishdate":"2021-03-16T09:22:39.463419Z","relpermalink":"/thegradient.pub/nlps-clever-hans-moment-has-arrived/","section":"publication","summary":"","tags":null,"title":"NLP's Clever Hans Moment has Arrived","type":"publication"},{"authors":["Yi Zhu","Benjamin Heinzerling","Ivan Vulić","Michael Strube","Roi Reichart","Anna Korhonen"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"b6339ac8469624dd0a8735f5d225a535","permalink":"https://bheinzerling.github.io/publication/zhu-2019-subword/","publishdate":"2019-11-08T07:36:28.992663Z","relpermalink":"/publication/zhu-2019-subword/","section":"publication","summary":"Recent work has validated the importance of subword information for word representation learning. Since subwords increase parameter sharing ability in neural models, their value should be even more pronounced in low-data regimes. In this work, we therefore provide a comprehensive analysis focused on the usefulness of subwords for word representation learning in truly low-resource scenarios and for three representative morphological tasks: fine-grained entity typing, morphological tagging, and named entity recognition. We conduct a systematic study that spans several dimensions of comparison: 1) type of data scarcity which can stem from the lack of task-specific training data, or even from the lack of unannotated data required to train word embeddings, or both; 2) language type by working with a sample of 16 typologically diverse languages including some truly low-resource ones (e.g. Rusyn, Buryat, and Zulu); 3) the choice of the subword-informed word representation method. Our main results show that subword-informed models are universally useful across all language types, with large gains over subword-agnostic embeddings. They also suggest that the effective use of subwords largely depends on the language (type) and the task at hand, as well as on the amount of available data for training the embeddings and task-based models, where having sufficient in-task data is a more critical requirement.","tags":null,"title":"On the Importance of Subword Information for Morphological Tasks in Truly Low-Resource Languages","type":"publication"},{"authors":["Pride Kavumba","Naoya Inoue","Benjamin Heinzerling","Keshav Singh","Paul Reisert","Kentaro Inui"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"92624f9808b6a4fdba17e4cc6d5b03dc","permalink":"https://bheinzerling.github.io/publication/kavumba-2019-choosing/","publishdate":"2019-11-08T07:36:15.506276Z","relpermalink":"/publication/kavumba-2019-choosing/","section":"publication","summary":"Pretrained language models, such as BERT and RoBERTa, have shown large improvements in the commonsense reasoning benchmark COPA. However, recent work found that many improvements in benchmarks of natural language understanding are not due to models learning the task, but due to their increasing ability to exploit superficial cues, such as tokens that occur more often in the correct answer than the wrong one. Are BERT′s and RoBERTa′s good performance on COPA also caused by this? We find superficial cues in COPA, as well as evidence that BERT exploits these cues.To remedy this problem, we introduce Balanced COPA, an extension of COPA that does not suffer from easy-to-exploit single token cues. We analyze BERT′s and RoBERTa′s performance on original and Balanced COPA, finding that BERT relies on superficial cues when they are present, but still achieves comparable performance once they are made ineffective, suggesting that BERT learns the task to a certain degree when forced to. In contrast, RoBERTa does not appear to rely on superficial cues.","tags":null,"title":"When Choosing Plausible Alternatives, Clever Hans can be Clever","type":"publication"},{"authors":["Federico López","Benjamin Heinzerling","Michael Strube"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"893bfd4bfbd371a6a78bcc0205b25110","permalink":"https://bheinzerling.github.io/publication/lopez-2019-finegrained/","publishdate":"2019-08-02T17:06:50.185526Z","relpermalink":"/publication/lopez-2019-finegrained/","section":"publication","summary":"How can we represent hierarchical information present in large type inventories for entity typing? We study the suitability of hyperbolic embeddings to capture hierarchical relations between mentions in context and their target types in a shared vector space. We evaluate on two datasets and propose two different techniques to extract hierarchical information from the type inventory: from an expert-generated ontology and by automatically mining the dataset. The hyperbolic model shows improvements in some but not all cases over its Euclidean counterpart. Our analysis suggests that the adequacy of this geometry depends on the granularity of the type inventory and the representation of its distribution.","tags":null,"title":"Fine-Grained Entity Typing in Hyperbolic Space","type":"publication"},{"authors":["Benjamin Heinzerling"],"categories":[],"content":"tl;dr: While the problem has been known for some time already, Niven \u0026amp; Kao present quite an egregious case of a neural network not learning what we think it learns.\nThe paper will appear at ACL 2019, preprint available here.\nIt is now almost a cliché to find out that BERT (Devlin et al., 2019) performs \u0026ldquo;surprisingly well\u0026rdquo; on whatever dataset you throw at it. In this paper, Niven \u0026amp; Kao throw an argument comprehension dataset and, as expected, were surprised to find that with random choice giving 50 percent accuracy, a knowledge-rich model getting 61 percent, and the previously best model achieving 71 percent by pre-training on a larger dataset for a related task, finetuned BERT wins hands down, getting 77 percent right.\nSo far, so BERT, but here comes the twist: Instead of submitting yet another \u0026ldquo;we haz SOTA, accept plox\u0026rdquo; type paper, the authors were suspicious of this seemingly great success. Argument comprehension is a rather difficult task that requires world knowledge and commonsense reasoning (see Figure 1), and while no one doubts that BERT is one of the best language models created yet, there is little evidence that language models are capable of such feats of high-level natural language understanding.\nThe Argument Reasoning Comprehension Task (Habernal et al., 2017, image source: Niven \u0026amp; Kao, 2019). Assuming a claim is made based on a given reason, select the piece of world knowledge (warrant or the alternative) that makes the claim valid. Here, the argument Google is not a harmful monopoly because people can choose not to use Google is valid \u0026ndash; or warranted in Toulmin\u0026rsquo;s terms \u0026ndash; if other search engines don\u0026rsquo;t redirect to Google, but invalid if all other search engines redirect to Google, because in the latter case users are forced to use Google, making Google a harmful monopoly. Sidenote: I think this example chosen by the authors is a bit unfortunate since it hinges on the strange use of redirect to meaning something like use search results provided by. The authors perform three analyses. First, they count unigrams and bigrams in the possible answers (i.e. warrants) and observe that the presence of a single unigram like not, is, or do predicts the correct warrant better than random chance, indicating that such cues are useful and probably exploited by the model. Then, to check if the model indeed exploits such cues, the authors provide the model only with partial input, which makes reasoning about the correct answer impossible: For example, it should not be possible to reason about whether other search engines don\u0026rsquo;t redirect to Google or all other search engines redirect to Google is the correct warrant if no claim or reason is given. However, the model doesn\u0026rsquo;t care about this impossibility and identifies the correct warrant with 71 percent accuracy. After running similar experiments for the other two task-breaking settings (claim and warrant only; reason and warrant only), the authors conclude that dataset contains statistical cues and that BERT\u0026rsquo;s performance on this task can be entirely explained by its ability to exploit these cues. To drive the point home, in their third experiment the authors construct a version of the dataset in which the cues are not informative anymore and find that performance drops to random chance level. Without getting into a Chinese Room argument about what it means to understand something, most people would probably agree that a model making predictions based on the presence or absence of a handful of words like \u0026ldquo;not\u0026rdquo;, \u0026ldquo;is\u0026rdquo;, or \u0026ldquo;do\u0026rdquo; does not understand anything about argumentation. The authors declare that their SOTA result is meaningless.\nOur main finding is that these results are not meaningful and should be discarded.\nOf course, the problem of learners solving a task by learning the \u0026ldquo;wrong\u0026rdquo; thing has been known for a long time and is known as the Clever Hans effect, after the eponymous horse which appeared to be able to perform simple intellectual tasks, but in reality relied on involuntary cues given by its handler. Since the 1960s, versions of the tank anecdote tell of a neural network trained by the military to recognize tanks in images, but actually learning to recognize different levels of brightness due to one type of tank appearing only in bright photos and another type only in darker ones. Less anecdotal, Viktoria Krakovna has collected a depressingly long list of agents following the letter, but not the spirit of their reward function, with such gems as a video game agent learning to die at the end of the first level, since repeating that easy level gives a higher score than dying early in the harder second level. Two more recent, but already infamous cases are an image classifier claimed to be able to distinguish faces of criminals from those of law-abiding citizens, but actually recognizing smiles and a supposed \u0026ldquo;sexual orientation detector\u0026rdquo; which can be better explained as a detector of glasses, beards and eyeshadow.\nIf NLP is following in the footsteps of computer vision, it seems to be doomed to repeat its failures, too. Coming back to the paper, the authors point to a (again, depressingly) large amount of recent work reporting Clever Hans effects in NLP datasets. Especially notable among related work is McCoy, Pavlick \u0026amp; Linzen\u0026rsquo;s Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference, which finds an instance of the Clever Hans effect in NLI, and comes to the same conclusions:\nStatistical learners such as standard neural network architectures are prone to adopting shallow heuristics that succeed for the majority of training examples, instead of learning the underlying generalizations that they are intended to capture.\nFor a broader view on this topic, also see Ana Marasović\u0026rsquo;s article on NLP\u0026rsquo;s Generalization Problem. To be clear, no one is claiming that large models like BERT or deep learning in general are useless (and I\u0026rsquo;ve found quite the opposite in my own work), but failures like the ones demonstrated in the paper and related work should make us skeptical about reports of near-human performance in high-level natural language understanding tasks.\nTwo minor gripes I have about the paper concern terminology. The authors call their second analysis \u0026ldquo;probing experiments\u0026rdquo;, but probing usually refers to training shallow classifiers on top of a deep neural network in order to determine what kind of information its representations contain, which is not done here. Similarly, the authors call the dataset they construct in their third analysis \u0026ldquo;adversarial dataset\u0026rdquo;, but adversarial usually refers to instances that mislead a model into making a wrong decision, which, again, is not done here. But these wording issues do not diminish the main findings of the paper.\nIn summary, Niven \u0026amp; Kao present a textbook case of the Clever Hans effect in NLP and remind us that as we train increasingly stronger learners, we need to pay increased attention to their ability of exploiting cues and taking unintended shortcuts.\nWhat does the Clever Hans effect mean for NLP? The growing number of papers finding cases of the Clever Hans effect raises important questions for NLP research, the most obvious one being how the effect can be prevented. When patterns in the dataset are aligned with the goal of the task at hand, a strong learner being able to recognize, remember, and generalize these patterns is desirable. But if the patterns are not what we\u0026rsquo;re actually interested in, then they become cues and shortcuts that allow the model to perform well without understanding the task. To prevent the Clever Hans effect, we hence need to aim for datasets without spurious patterns, and we need to assume that a well-performing model didn\u0026rsquo;t learn anything useful until proven otherwise. I\u0026rsquo;ll make suggestions for improving datasets first, then one for improving models.\nDatasets need more love Coming up with a model and improving it gives instant gratification from seeing the score go up during development, and SOTA on a common dataset all but ensures paper acceptance and ensuing citations. The gratification for creating a dataset is much more delayed and much less certain. Anecdotally, the default *ACL conference reviewer stance towards a paper proposing a novel1 model getting SOTA2 seems to be \u0026ldquo;accept\u0026rdquo;, while a paper introducing a new dataset needs to fight against a \u0026ldquo;this paper only introduces a new dataset -\u0026gt; reject\u0026rdquo; attitude: People who create datasets are not doing real science, and while they\u0026rsquo;re free to have their own little conference in exotic locations, they obviously are not smart enough to import tensorflow as tf, so they shouldn\u0026rsquo;t pollute top tier conferences with their boring resource papers. This post by Rachel Bawden gives examples of this kind of reviewer attitude.\nOf course, not all resource papers can be published at top conferences with low acceptance rates, but if we have to choose between having too many models or too many datasets, I\u0026rsquo;d argue more datasets will have a more solid and lasting positive impact. Better acceptance prospects will encourage more researchers to create datasets, which will give us more and (hopefully) better datasets, which, in turn, will allow overcoming the current dataset monoculture with one \u0026ldquo;standard\u0026rdquo; dataset per task, and the resulting dataset diversity will, finally, allow more robust evaluation of models.\nDataset ablations and public betas Ablating, i.e. removing, part of a model and observing the impact this has on performance is a common method for verifying that the part in question is useful. If performance doesn\u0026rsquo;t go down, then the part is useless and should be removed. Carrying this method over to datasets, it should become common practice to perform dataset ablations, as well, for example:\nProvide only incomplete input (as done in the reviewed paper): This verifies that the complete input is required. If not, the dataset contains cues that allow taking shortcuts. Shuffle the input: This verifies the importance of word (or sentence) order. If a bag-of-words/sentences gives similar results, even though the task requires sequential reasoning, then the model has not learned sequential reasoning and the dataset contains cues that allow the model to \u0026ldquo;solve\u0026rdquo; the task without it. Assign random labels: How much does performance drop if ten percent of instances are relabeled randomly? How much with all random labels? If scores don\u0026rsquo;t change much, the model probably didn\u0026rsquo;t learning anything interesting about the task. Randomly replace content words: How much does performance drop if all noun phrases and/or verb phrases are replaced with random noun phrases and verbs? If not much, the dataset may provide unintended non-content cues, such as sentence length or distribution of function words. New datasets could be improved and verified by initially treating them as being in a public beta phase, in which claims are made only in terms of performance on dataset X and not in terms of performance in task Y. Model creators using a dataset in public beta would also have to perform dataset ablations until we can be reasonably sure that the dataset contains no simple cues or shortcuts.\nInter-prediction agreement If, for example, adding an unrelated sentence to the input causes a question-answering model to give a different answer (see Figure 2), the model is not really understanding the question. Rather, it seems to have learned heuristics like if the question contains the words \u0026ldquo;what\u0026rdquo; and \u0026ldquo;name\u0026rdquo; the answer is the first proper noun phrase in the last sentence.\nA question-answering model being fooled by a meaning-preserving addition of an unrelated sentence, shown in blue (Source: Jia and Liang, 2017). Failures like these mean that we should not only aim to create better models that co-evolve with increasingly difficult datasets, as proposed by Zellers et al. (2019), but also improve models by making them more robust. Towards this goal, model creators need to adopt a Build It, Break It mentality, according to which it is not enough to get a high score on a certain dataset, but also necessary to test a model\u0026rsquo;s robustness. Such tests could be done by something akin to fuzzing in software testing, where an attacker attempts to find inputs that cause a system to fail.\nIf dataset creators have to report inter-annotator agreement to allow judging the consistency of annotations, we should require model creators to report inter-prediction agreement to allow judging the consistency of model predictions. Such a score could be calculated on sets of semantically equivalent instances, e.g. as the proportion of predictions that remain the same under meaning-preserving perturbations of a test instance.\nThe importance of being novel cannot be overstated. A paper proposing a model that is merely new has little chance of being accepted.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAlso see Anna Rogers\u0026rsquo; critique of the SOTA-centric approach to NLP.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1563719959,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563719959,"objectID":"12ca69a6cfff445531a26d82be1a516b","permalink":"https://bheinzerling.github.io/post/clever-hans/","publishdate":"2019-07-21T23:39:19+09:00","relpermalink":"/post/clever-hans/","section":"post","summary":"A review of Timothy Niven and Hung-Yu Kao, 2019: Probing Neural Network Comprehension of Natural Language Arguments.","tags":[],"title":"NLP's Clever Hans Moment has Arrived","type":"post"},{"authors":["Benjamin Heinzerling","Michael Strube"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"312fa04ce83edb9e13e3db5d3e14eade","permalink":"https://bheinzerling.github.io/publication/heinzerling-2019-sequence/","publishdate":"2019-07-23T03:48:44.369816Z","relpermalink":"/publication/heinzerling-2019-sequence/","section":"publication","summary":"","tags":null,"title":"Sequence Tagging with Contextual and Non-Contextual Subword Representations: A Multilingual Evaluation","type":"publication"},{"authors":["Benjamin Heinzerling","Michael Strube"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"ebeb3b2818b288ce3b9684607660a102","permalink":"https://bheinzerling.github.io/publication/heinzerling-2018-bpemb/","publishdate":"2019-07-23T03:48:44.372067Z","relpermalink":"/publication/heinzerling-2018-bpemb/","section":"publication","summary":"","tags":null,"title":"BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages","type":"publication"},{"authors":["Markus Zopf","Teresa Botschen","Tobias Falke","Beniamin Heinzerling","Ana Marasovic","Todor Mihaylov","PVS Avinesh","Eneldo Loza Mencia","Johannes Fürnkranz","Anette Frank"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"2df08c20e8cf21cc9f990d6b5480f653","permalink":"https://bheinzerling.github.io/publication/zopf-2018-important/","publishdate":"2019-07-23T03:48:44.371234Z","relpermalink":"/publication/zopf-2018-important/","section":"publication","summary":"","tags":null,"title":"What's important in a text? An extensive evaluation of linguistic annotations for summarization","type":"publication"},{"authors":["Benjamin Heinzerling","Nafise Sadat Moosavi","Michael Strube"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"4bfd8a11e36d668360e446d7a5145d32","permalink":"https://bheinzerling.github.io/publication/heinzerling-2017-selectional/","publishdate":"2020-07-08T09:05:33.013719Z","relpermalink":"/publication/heinzerling-2017-selectional/","section":"publication","summary":"","tags":null,"title":"Revisiting Selectional Preferences for Coreference Resolution","type":"publication"},{"authors":["Benjamin Heinzerling","Michael Strube","Chin-Yew Lin"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"62424200ad7e67513ea856654857d7bd","permalink":"https://bheinzerling.github.io/publication/heinzerling-2017-trust/","publishdate":"2019-07-23T03:48:44.373606Z","relpermalink":"/publication/heinzerling-2017-trust/","section":"publication","summary":"","tags":null,"title":"Trust, but Verify! Better Entity Linking through Automatic Verification","type":"publication"},{"authors":["Benjamin Heinzerling","Michael Strube"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"78cf7557f4cf9242cfa7860ff6a200c2","permalink":"https://bheinzerling.github.io/publication/heinzerling-2015-visual/","publishdate":"2019-07-23T03:48:44.375044Z","relpermalink":"/publication/heinzerling-2015-visual/","section":"publication","summary":"","tags":null,"title":"Visual Error Analysis for Entity Linking","type":"publication"},{"authors":["Benjamin Heinzerling","Alex Judea","Michael Strube"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"f7d0520547a586f125be730947b5b546","permalink":"https://bheinzerling.github.io/publication/heinzerling-2015-tac/","publishdate":"2019-07-23T03:48:44.374392Z","relpermalink":"/publication/heinzerling-2015-tac/","section":"publication","summary":"","tags":null,"title":"HITS at TAC KBP 2015: Entity discovery and linking, and event nugget detection","type":"publication"},{"authors":[" Alex Judea","Benjamin Heinzerling","Michael Strube"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"c9523db6f84e76b143ae829195e97480","permalink":"https://bheinzerling.github.io/publication/judea-2014-tac/","publishdate":"2019-07-23T03:48:44.375751Z","relpermalink":"/publication/judea-2014-tac/","section":"publication","summary":"","tags":null,"title":"HITS' Monolingual and Cross-lingual Entity Linking System at TAC 2014","type":"publication"},{"authors":["Angela Fahrni","Benjamin Heinzerling","Thierry Göckel","Michael Strube"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"2f2900f079d36334030e7e32f54b4087","permalink":"https://bheinzerling.github.io/publication/fahrni-2013-tac/","publishdate":"2019-07-23T03:48:44.3763Z","relpermalink":"/publication/fahrni-2013-tac/","section":"publication","summary":"","tags":null,"title":"HITS' Monolingual and Cross-lingual Entity Linking System at TAC 2013","type":"publication"}]